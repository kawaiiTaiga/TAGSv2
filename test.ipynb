{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation 과정 분산처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class Generation_model():\n",
    "    def __init__(self, device) -> None:\n",
    "        self.device = torch.device(f\"cuda:{device}\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model =  LlamaForCausalLM.from_pretrained(\"chavinlo/alpaca-native\",low_cpu_mem_usage=True,torch_dtype='auto').to(self.device)\n",
    "        self.tokenizer = LlamaTokenizer.from_pretrained(\"chavinlo/alpaca-native\")\n",
    "        self.device_number = device\n",
    "    def generate(self,input_samples):\n",
    "        candidate_list = []\n",
    "        placeholders  = \"'{}',\"* 1\n",
    "        formatted_prompt = f\"prompt promp\" + placeholders + \"PROMPT PROMPT {}\".format(input_samples) \n",
    "        print(input_samples)\n",
    "        for input_sample in input_samples:\n",
    "            prompt = formatted_prompt.format(*input_sample[1])\n",
    "            inputs = self.tokenizer.encode(formatted_prompt,return_tensors=\"pt\").to(self.device)\n",
    "            candidate_senetnces = self.model.generate(inputs) #make to candidate format\n",
    "            text = self.tokenizer.decode(*candidate_senetnces)\n",
    "            candidate_list.append([input_sample[0],text])\n",
    "\n",
    "        return candidate_list\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlp-04/anaconda3/envs/kkm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset csv (/home/nlp-04/.cache/huggingface/datasets/ml4pubmed___csv/ml4pubmed--pubmed-classification-20k-3de662485795ef5d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "100%|██████████| 3/3 [00:00<00:00, 446.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from Generation.generation_model import Generation_model\n",
    "from utils import *\n",
    "import asyncio\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "from huggingface_hub import hf_hub_download\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import AutoTokenizer, LlamaForCausalLM,LlamaTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ml4pubmed/pubmed-classification-20k\")\n",
    "original_data = preprocess_dataset(dataset['train'])\n",
    "few_data = list(make_fewshot_dataset(original_data,2).items())\n",
    "sublists_length = int(len(few_data)/2)\n",
    "sublists = [few_data[i:i+sublists_length] for i in range(0, len(few_data), sublists_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.97s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.99s/it]\n"
     ]
    }
   ],
   "source": [
    "async def generation_with_model_1(Generation_model = None):\n",
    "    return Generation_model.generate(sublists[Generation_model.device_number])\n",
    "\n",
    "models = [Generation_model(device_number) for device_number in range(2)]\n",
    "async_list = [generation_with_model_1(model) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('OBJECTIVE', ['To assess the optimal scan delays and contrast injection durations for contrast-enhanced whole-body computed tomography ( CT ) .', 'The cross-sectional FOCUS ( Fixed-Dose Combination Drug for Secondary Cardiovascular Prevention ) study ( Phase 1 ) aimed to elucidate factors that interfere with appropriate adherence to CV medications for secondary prevention after an acute MI .']), ('METHODS', ['This large , multicenter , simulated-use study evaluated whether adults ( aged 18-65 years ) , caregivers ( parents/guardians aged 18-65 years of children aged 5-17 years ) , and children ( aged 11-17 years ) , with and without experience in using an EAI , had a preference for the current design of Auvi-Q or the current design of EpiPen .', 'Forty patients were treated with RF and 40 with Cryo .'])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlp-04/anaconda3/envs/kkm/lib/python3.10/site-packages/transformers/generation/utils.py:1201: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('RESULTS', ['We analysed the rates of stroke and systemic embolism in 6563 aspirin-treated patients with AF from the ACTIVE-A/AVERROES databases .', 'LPV/r-based ART was superior to NVP-based ART for efficacy and safety outcomes ; however , those on NVP had larger improvements in CD4 % , weight and height z-scores .']), ('CONCLUSIONS', [\"OW individuals ' brain responses to food stimuli may indicate greater reward incentive processes than either SWL or NW groups .\", 'Extended use of an alcohol-based mouthrinse is no more likely to cause reduction in salivary flow or perceived dryness in individuals with normal salivary flow compared with a non-alcohol-based mouthrinse ( CPH ) .'])]\n"
     ]
    }
   ],
   "source": [
    "async def generation_with_model_1(Generation_model = None):\n",
    "    return Generation_model.generate(sublists[Generation_model.device_number])\n",
    "    \n",
    "    await asyncio.sleep(0)\n",
    "async_list = [generation_with_model_1(model) for model in models]\n",
    "async def main():\n",
    "    results = await asyncio.gather(\n",
    "        *async_list\n",
    "    )\n",
    "    return results\n",
    "    \n",
    "\n",
    "\n",
    "result = await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['OBJECTIVE', ' prompt promp\\'{}\\',PROMPT PROMPT [(\\'OBJECTIVE\\', [\\'To assess the optimal scan delays and contrast injection durations for contrast-enhanced whole-body computed tomography ( CT ).\\', \\'The cross-sectional FOCUS ( Fixed-Dose Combination Drug for Secondary Cardiovascular Prevention ) study ( Phase 1 ) aimed to elucidate factors that interfere with appropriate adherence to CV medications for secondary prevention after an acute MI.\\']), (\\'METHODS\\', [\\'This large, multicenter, simulated-use study evaluated whether adults ( aged 18-65 years ), caregivers ( parents/guardians aged 18-65 years of children aged 5-17 years ), and children ( aged 11-17 years ), with and without experience in using an EAI, had a preference for the current design of Auvi-Q or the current design of EpiPen.\\', \\'Forty patients were treated with RF and 40 with Cryo.\\'])]\\n\\ndef extract_paragraphs(paragraphs):\\n    paragraphs_list = paragraphs.split(\"\\\\n\\\\n\")\\n    return'], ['METHODS', ' prompt promp\\'{}\\',PROMPT PROMPT [(\\'OBJECTIVE\\', [\\'To assess the optimal scan delays and contrast injection durations for contrast-enhanced whole-body computed tomography ( CT ).\\', \\'The cross-sectional FOCUS ( Fixed-Dose Combination Drug for Secondary Cardiovascular Prevention ) study ( Phase 1 ) aimed to elucidate factors that interfere with appropriate adherence to CV medications for secondary prevention after an acute MI.\\']), (\\'METHODS\\', [\\'This large, multicenter, simulated-use study evaluated whether adults ( aged 18-65 years ), caregivers ( parents/guardians aged 18-65 years of children aged 5-17 years ), and children ( aged 11-17 years ), with and without experience in using an EAI, had a preference for the current design of Auvi-Q or the current design of EpiPen.\\', \\'Forty patients were treated with RF and 40 with Cryo.\\'])]\\n\\ndef extract_paragraphs(paragraphs):\\n    paragraphs_list = paragraphs.split(\"\\\\n\\\\n\")\\n    return']], [['RESULTS', ' prompt promp\\'{}\\',PROMPT PROMPT [(\\'RESULTS\\', [\\'We analysed the rates of stroke and systemic embolism in 6563 aspirin-treated patients with AF from the ACTIVE-A/AVERROES databases.\\', \\'LPV/r-based ART was superior to NVP-based ART for efficacy and safety outcomes ; however, those on NVP had larger improvements in CD4 %, weight and height z-scores.\\']), (\\'CONCLUSIONS\\', [\"OW individuals\\'brain responses to food stimuli may indicate greater reward incentive processes than either SWL or NW groups.\", \\'Extended use of an alcohol-based mouthrinse is no more likely to cause reduction in salivary flow or perceived dryness in individuals with normal salivary flow compared with a non-alcohol-based mouthrinse ( CPH ).\\'])]\\n\\ndef extract_paragraphs(text):\\n    text_lst = text.split()\\n    return text_lst\\n\\ndef extract'], ['CONCLUSIONS', ' prompt promp\\'{}\\',PROMPT PROMPT [(\\'RESULTS\\', [\\'We analysed the rates of stroke and systemic embolism in 6563 aspirin-treated patients with AF from the ACTIVE-A/AVERROES databases.\\', \\'LPV/r-based ART was superior to NVP-based ART for efficacy and safety outcomes ; however, those on NVP had larger improvements in CD4 %, weight and height z-scores.\\']), (\\'CONCLUSIONS\\', [\"OW individuals\\'brain responses to food stimuli may indicate greater reward incentive processes than either SWL or NW groups.\", \\'Extended use of an alcohol-based mouthrinse is no more likely to cause reduction in salivary flow or perceived dryness in individuals with normal salivary flow compared with a non-alcohol-based mouthrinse ( CPH ).\\'])]\\n\\ndef extract_paragraphs(text):\\n    text_lst = text.split()\\n    return text_lst\\n\\ndef extract']]]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The median time to prostate-specific antigen progression was 4.7 months ( 95 % confidence interval 3.7-8 .3 ) ; the median overall survival was 11.8 months .', 'There was a weak correlation between prior contraceptive compliance and education level .']\n",
      "prompt promp'The median time to prostate-specific antigen progression was 4.7 months ( 95 % confidence interval 3.7-8 .3 ) ; the median overall survival was 11.8 months .',PROMPT PROMPT There was a weak correlation between prior contraceptive compliance and education level .\n"
     ]
    }
   ],
   "source": [
    "d = ['The median time to prostate-specific antigen progression was 4.7 months ( 95 % confidence interval 3.7-8 .3 ) ; the median overall survival was 11.8 months .', 'There was a weak correlation between prior contraceptive compliance and education level .']\n",
    "print(d)\n",
    "placeholders  = \"'{}',\"* 1\n",
    "formatted_prompt = \"prompt promp\" + placeholders + \"PROMPT PROMPT {}\" \n",
    "prompt = formatted_prompt.format(*d)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(Generation_model\u001b[39m.\u001b[39mgenerate(\u001b[39m\"\u001b[39m\u001b[39mhello\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      3\u001b[0m async_list \u001b[39m=\u001b[39m [generation_with_model_1(model) \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models]\n\u001b[0;32m----> 4\u001b[0m b\u001b[39m=\u001b[39m  generation_with_model_1(model1)\n\u001b[1;32m      5\u001b[0m c \u001b[39m=\u001b[39m  generation_with_model_1(model2)\n\u001b[1;32m      6\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model1' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "async def generation_with_model_1(Generation_model = None):\n",
    "    print(Generation_model.generate(\"hello\"))\n",
    "async_list = [generation_with_model_1(model) for model in models]\n",
    "b=  generation_with_model_1(model1)\n",
    "c =  generation_with_model_1(model2)\n",
    "async def main():\n",
    "    await asyncio.gather(\n",
    "        b,c\n",
    "    )\n",
    "    print(\"finsh\")\n",
    "\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "An asyncio.Future, a coroutine or an awaitable is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mawait\u001b[39;00m main()\n",
      "Cell \u001b[0;32mIn[3], line 19\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m():\n\u001b[0;32m---> 19\u001b[0m     \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39;49mgather(\n\u001b[1;32m     20\u001b[0m         \u001b[39m*\u001b[39;49masync_list\n\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     22\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mfinsh\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda/envs/kkm/lib/python3.9/asyncio/tasks.py:756\u001b[0m, in \u001b[0;36mgather\u001b[0;34m(loop, return_exceptions, *coros_or_futures)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[39mif\u001b[39;00m loop \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    752\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe loop argument is deprecated since Python 3.8, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    753\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39mand scheduled for removal in Python 3.10.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    754\u001b[0m                   \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m--> 756\u001b[0m \u001b[39mreturn\u001b[39;00m _gather(\u001b[39m*\u001b[39;49mcoros_or_futures, loop\u001b[39m=\u001b[39;49mloop, return_exceptions\u001b[39m=\u001b[39;49mreturn_exceptions)\n",
      "File \u001b[0;32m~/anaconda/envs/kkm/lib/python3.9/asyncio/tasks.py:829\u001b[0m, in \u001b[0;36m_gather\u001b[0;34m(loop, return_exceptions, *coros_or_futures)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m coros_or_futures:\n\u001b[1;32m    828\u001b[0m     \u001b[39mif\u001b[39;00m arg \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m arg_to_fut:\n\u001b[0;32m--> 829\u001b[0m         fut \u001b[39m=\u001b[39m ensure_future(arg, loop\u001b[39m=\u001b[39;49mloop)\n\u001b[1;32m    830\u001b[0m         \u001b[39mif\u001b[39;00m loop \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    831\u001b[0m             loop \u001b[39m=\u001b[39m futures\u001b[39m.\u001b[39m_get_loop(fut)\n",
      "File \u001b[0;32m~/anaconda/envs/kkm/lib/python3.9/asyncio/tasks.py:677\u001b[0m, in \u001b[0;36mensure_future\u001b[0;34m(coro_or_future, loop)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[39mreturn\u001b[39;00m ensure_future(_wrap_awaitable(coro_or_future), loop\u001b[39m=\u001b[39mloop)\n\u001b[1;32m    676\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAn asyncio.Future, a coroutine or an awaitable is \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    678\u001b[0m                     \u001b[39m'\u001b[39m\u001b[39mrequired\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: An asyncio.Future, a coroutine or an awaitable is required"
     ]
    }
   ],
   "source": [
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2558908/2895284244.py:3: RuntimeWarning: coroutine 'generation_with_model_1' was never awaited\n",
      "  globals()[f\"hell{a}\"] = generation_with_model_1(a)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "async_list = []\n",
    "for a in range(2):\n",
    "    globals()[f\"hell{a}\"] = generation_with_model_1(a)\n",
    "    async_list.append(f\"hell{a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hell'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlp-04/anaconda3/envs/kkm/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset csv (/home/nlp-04/.cache/huggingface/datasets/ml4pubmed___csv/ml4pubmed--pubmed-classification-20k-3de662485795ef5d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "100%|██████████| 3/3 [00:00<00:00, 469.55it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ml4pubmed/pubmed-classification-20k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'###24854809'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# 리스트 순회하며 라벨에 따라 요소를 분류\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m dataset[\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m---> 14\u001b[0m     label_dict[item[\u001b[39m'\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m'\u001b[39;49m]]\u001b[39m.\u001b[39mappend(item[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     16\u001b[0m \u001b[39m# 결과 출력\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m label, values \u001b[39min\u001b[39;00m label_dict\u001b[39m.\u001b[39mitems():\n",
      "\u001b[0;31mKeyError\u001b[0m: '###24854809'"
     ]
    }
   ],
   "source": [
    "labels = set()\n",
    "\n",
    "# 유니크한 라벨 추출\n",
    "for item in dataset['train']:\n",
    "    label = item['label']\n",
    "    labels.add(label)\n",
    "\n",
    "labels = ['RESULTS','METHODS','OBJECTIVE','CONCLUSIONS']\n",
    "# 라벨에 따라 요소를 분류할 딕셔너리 초기화\n",
    "label_dict = {label: [] for label in labels}\n",
    "\n",
    "# 리스트 순회하며 라벨에 따라 요소를 분류\n",
    "for item in dataset['train']:\n",
    "    label_dict[item['label']].append(item['text'])\n",
    "\n",
    "# 결과 출력\n",
    "for label, values in label_dict.items():\n",
    "    print(label + ':', values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = list(set(get_labels(dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/nlp-04/.cache/huggingface/datasets/ml4pubmed___csv/ml4pubmed--pubmed-classification-20k-3de662485795ef5d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "100%|██████████| 3/3 [00:00<00:00, 584.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ml4pubmed/pubmed-classification-20k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "# 레이블 정보 가져오기\n",
    "    labels = dataset['label']  # 훈련 데이터셋의 레이블 가져오기\n",
    "\n",
    "    # 레이블에 해당하는 인덱스 식별하기\n",
    "    label_indices = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        if label not in label_indices:\n",
    "            label_indices[label] = []\n",
    "        label_indices[label].append(i)\n",
    "\n",
    "    # 레이블별로 데이터 저장할 리스트 생성\n",
    "    label_lists = {}\n",
    "    for label, indices in label_indices.items():\n",
    "        if len(indices) > 1:  # 데이터가 있는 경우에만 리스트 생성\n",
    "            label_lists[label] = []\n",
    "\n",
    "    # 레이블별로 데이터 저장\n",
    "    for label, indices in label_indices.items():\n",
    "        if label in label_lists:  # 데이터가 있는 레이블에 대해서만 처리\n",
    "            for index in indices:\n",
    "                data = dataset[index]  # 데이터 가져오기 (여기서는 예시로 훈련 데이터셋 사용)\n",
    "                label_lists[label].append(data['text'])\n",
    "    return label_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = preprocess_dataset(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def make_fewshot_dataset(label_lists,num_samples):\n",
    "    fewshot_data = {}\n",
    "    for label,all_data in label_lists.items():\n",
    "        few_data = random.sample(all_data,num_samples)\n",
    "        fewshot_data[label] = few_data\n",
    "    return fewshot_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('OBJECTIVE',\n",
       "   ['To evaluate the efficacy of a combined neurolytic block of the celiac and superior hypogastric plexuses for incapacitating upper abdominal cancer pain .',\n",
       "    'To investigate the role of preoperative biometry for selecting initial contact lens power .']),\n",
       "  ('METHODS',\n",
       "   ['Children aged 9-12years from both sexes were randomly assigned to one of six groups to receive plain milk , fortified milk , plain orange juice , fortified orange juice , supplement or placebo .',\n",
       "    'Fasting blood samples were taken at baseline and after an 8-week intervention for quantification of related factors .']),\n",
       "  ('RESULTS',\n",
       "   ['No significant differences were found in the expression of sarcoplasmic reticulum Ca ( 2 + ) ATPase ( SERCA2a ) and ryanodine receptors ( RyRs ) .',\n",
       "    'In an analysis controlling for level , degree , and number of anchors , tranexamic acid reduced drain output and total blood losses .']),\n",
       "  ('CONCLUSIONS',\n",
       "   ['However , there is a need for further research to be considered as an alternative to chlorhexidine for prevention of VALP in ICU patients .',\n",
       "    '( Funded by a consortium of eight device and drug manufacturers and others ; DAPT ClinicalTrials.gov number , NCT00977938 . )'])],\n",
       " [('BACKGROUND',\n",
       "   ['Current treatments for low back pain have small effects .',\n",
       "    'Acupuncture is commonly used to reduce pain during labour despite contradictory results .'])]]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_data = list(make_fewshot_dataset(b,2).items())\n",
    "sublists_length = 4 #class length / device lenght\n",
    "sublists = [few_data[i:i+sublists_length] for i in range(0, len(few_data), sublists_length)]\n",
    "sublists"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kkm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
